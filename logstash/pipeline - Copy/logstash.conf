input {
  beats {
    port => 5044
  }
}

filter {

	if [log_type] == "maintaince_jira"{
		csv {
				separator => ","
				columns => ["Key","Client Name","Priority","Summary","Closed","Component/s","Internal Status","Status","Created","Updated","Initial Priority","Resolution","Affects Version/s","Software Environment","Resolved","Release Priority","Linked Issues","Sprint","Security Level","Assignee Group","Assignee Dev L2","Assignee Dev L3"]
			}
	}
	if [log_type] == "vaibhav_jira"{		
		csv {
				separator => ","
				columns => ["Key","Client_Name","Priority","Summary","Closed","Component","Internal_Status","Status","Created","Updated","Initial_Priority","Resolution","Affects_Version","Software_Environment","Resolved","Release Priority","Linked_Issues","Sprint","Security_Level","Assignee_Group","Assignee_Dev_L2","Assignee_Dev_L3"]
			}	
		grok {
				match => [ "Affects_Version" ,"%{NUMBER:Affects_Version_Vanilla:Double}"]
			 }
		grok {
				match => [ "Affects_Version" ,"%{INT:Main_Version}"]
			 }
		mutate {
				add_field => {"Main_Branch" =>  "%{Main_Version}.x" }
		}
		
#		grok {
#				match => [ "Created" ,"%{URIHOST:created_dt}"]
#		}
		
		date {
				match => [ "Created" ,"dd-MM-yyyy hh:mm"]
				target => created_dt1
		}
		
		#		date {
		#		match => [ "created_dt" ,"DD-MM-YYYY"]
		#		target => created_dt2
		#}


	}
	
	if [log_type] == "valuation_log"{
		grok {
				match => [ "message" ,"%{TIMESTAMP_ISO8601:valuation_timestamp} \[%{DATA:thread_id}\] %{NOTSPACE:task} %{GREEDYDATA} - %{DATA},%{NUMBER:batch_size:int},%{DATA},%{NUMBER:num_of_positions:int},%{DATA},%{NUMBER:num_of_cashflows:int},%{DATA},%{NUMBER:num_of_batches:int},%{DATA},%{NUMBER:avg_position_write_time:int},%{DATA},%{NUMBER:avg_cashflow_update_time:int},%{DATA},%{NUMBER:avg_batch_set_optimal_position_keys_time:int},%{DATA},%{NUMBER:avg_batch_term_purge_action_time:int},%{DATA},%{NUMBER:avg_db_error_handler_action_time:int},%{DATA},%{NUMBER:avg_batch_term_update_eod_status_action_time:int},%{DATA},%{NUMBER:avg_batch_valuation_time:int},%{DATA},%{NUMBER:total_eod_time:int}"]
			}
			
	}
	if [log_type] == "tpt_metric" {
		json {
			source => "message"
		}
	}
	
	if [log_type] == "tpt_log" {
		grok {
				match => [ "message" , "%{TIMESTAMP_ISO8601:cxl_timestamp_temp} \[%{DATA:cxl_thread}\] %{LOGLEVEL:cxl_log_level} .*?TradeDataServiceImpl - Term Data Load Time:%{NUMBER:TVC_TERM_LOAD_TIME:int}"]
			 }
	}
	if [log_type] == "tpt_log" {
		grok {
				match => [ "message" , "%{TIMESTAMP_ISO8601:cxl_timestamp_temp} \[%{DATA:cxl_thread}\] %{LOGLEVEL:cxl_log_level} .*?TradeDataServiceImpl - Term Data XML conversion Time:%{NUMBER:TVC_TERM_XML_CONVERSION_TIME:int}"]
			 }
	}
	if [log_type] == "tpt_log" {
		grok {
				match => [ "message" , "%{TIMESTAMP_ISO8601:cxl_timestamp_temp} \[%{DATA:cxl_thread}\] .*?JMS Send and Receive Time diff :%{NUMBER:TVC_JMS_MSG_QUEUE_TIME:int}"]
			 }
	}	
}


output {
	if [log_type] == "tpt_log" {
		elasticsearch {
			hosts => ["10.101.160.48:9200","10.101.160.48:9300"]
			manage_template => false
			index => "cxl2-ci-log-%{+YYYY.MM.dd}"
		}
	} 
	
	if [log_type] == "tpt_metric" {
		elasticsearch {
			hosts => ["10.101.160.48:9200","10.101.160.48:9300"]
			manage_template => false
			index => "cxl2-ci-ph-%{+YYYY.MM.dd}"
		}
	}
	
	if [log_type] == "maintaince_jira"{
		elasticsearch {
				hosts => ["10.101.160.48:9200","10.101.160.48:9300"]
				manage_template => false
				index => "maintaince-jira-%{+YYYY.MM.dd}"
			}
	}
	if [log_type] == "vaibhav_jira"{
		elasticsearch {
				hosts => ["10.101.160.48:9200","10.101.160.48:9300"]
				manage_template => false
				index => "vaibhav-jira-%{+YYYY.MM.dd}"
			}
	}
	
	if [log_type] == "valuation_log"{
		# if not any parse exception msg is valid, hence emit fields
		if !("_grokparsefailure" in [tags]) {
			elasticsearch {
					hosts => ["10.101.160.48:9200"]
					manage_template => false
					index => "nve-metrics-%{+YYYY.MM.dd}"
				}
			stdout { codec => rubydebug }
		}
	}
	
	
}